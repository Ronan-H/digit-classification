{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting off with imports and ignoring warnings (to make things a bit tidier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# from https://stackoverflow.com/questions/9031783/hide-all-warnings-in-ipython\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras import Sequential\n",
    "from keras import layers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure my GPU is found, so the training can be done on my graphics card.\n",
    "\n",
    "(this notebook should still work without a compatible graphics card set up, though)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "# from https://www.tensorflow.org/guide/gpu\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the MNIST data set\n",
    "Keras comes packed with some commonly used data sets, including the MNIST handwritten digit database.\n",
    "\n",
    "This makes it very easy to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://keras.io/datasets/#mnist-database-of-handwritten-digits\n",
    "(x_train_raw, y_train_raw), (x_test_raw, y_test_raw) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to convert the data set values into a form that fits our model.\n",
    "\n",
    "This includes converting the labels into a binary class matrix, and reshaping the digit pixel values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://keras.io/getting-started/sequential-model-guide/\n",
    "y_train = keras.utils.to_categorical(y_train_raw, num_classes=10, dtype=\"uint8\")\n",
    "y_test = keras.utils.to_categorical(y_test_raw, num_classes=10, dtype=\"uint8\")\n",
    "\n",
    "x_train = x_train_raw.reshape(60000,28,28,1)\n",
    "x_test = x_test_raw.reshape(10000,28,28,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how a single digit can be rendered on a graph using MatPlotLib.\n",
    "\n",
    "Note that the pixel values are inverted, because the MNIST data set is white on a black background, while typically you would expect it to be the other way around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Label: 5'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2ea0d92898>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.imshow([255 - i for i in x_train_raw[0]], cmap='gray')\n",
    "\"Label: {}\".format(y_train_raw[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is where the model gets built. I decided to use a convolutional neural network for my model, because they perform very well for image classification problems.\n",
    "\n",
    "I watched [this](https://youtu.be/py5byOOHZM8) video by Computerphile to learn how CNNs work.\n",
    "\n",
    "The basic idea is that at each convolutional layer (Conv2D), a [kernel](https://en.wikipedia.org/wiki/Kernel_(image_processing)) is passed over the image, extracting many different features (eg. edges). Since I use two convolutional layers, a kernal is passed again over those features to produce another, smaller, set of features. During backpropagation, the neural network can figure out how the features relate to the digits 0-9, and produce a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/building-a-convolutional-neural-network-cnn-in-keras-329fbbadc5f5\n",
    "# https://towardsdatascience.com/deciding-optimal-filter-size-for-cnns-d6f7b56f9363\n",
    "# https://keras.io/layers/convolutional/\n",
    "# https://keras.io/examples/mnist_cnn/\n",
    "model = Sequential()\n",
    "\n",
    "# pull out big features in the layer (large kernel)\n",
    "model.add(layers.Conv2D(32, kernel_size=5, activation=\"relu\", input_shape=(28,28,1)))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "# pull out smaller features from these big features (small kernel)\n",
    "model.add(layers.Conv2D(32, kernel_size=3, activation=\"relu\"))\n",
    "model.add(layers.Conv2D(64, kernel_size=3, activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "# finally, a simple dense layer\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This trains the model.\n",
    "\n",
    "**Epoch:** One complete pass over the training set. 10 epochs = 10 passes over the training data.\n",
    "\n",
    "**Batch size:** Number of digits to train on the network in one go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/18\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 1.4110 - accuracy: 0.7327\n",
      "Epoch 2/18\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.1808 - accuracy: 0.9454\n",
      "Epoch 3/18\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.1242 - accuracy: 0.9637\n",
      "Epoch 4/18\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.0978 - accuracy: 0.9705\n",
      "Epoch 5/18\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.0825 - accuracy: 0.9758\n",
      "Epoch 6/18\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.0711 - accuracy: 0.9786\n",
      "Epoch 7/18\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.0649 - accuracy: 0.9803\n",
      "Epoch 8/18\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.0576 - accuracy: 0.9825\n",
      "Epoch 9/18\n",
      " 6500/60000 [==>...........................] - ETA: 2s - loss: 0.0471 - accuracy: 0.9862"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=18, batch_size=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model on the test set.\n",
    "\n",
    "(60,000 digits are for training, and the remaining 10,000 are for testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(x_test, y_test)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "May as well train on the test data now too, with less epochs because it's a smaller set of data (10,000 instead of 60,000 images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_test, y_test, epochs=3, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model to disk, to be later read back in on the Flask server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://machinelearningmastery.com/save-load-keras-deep-learning-models/\n",
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a demonstration of the model, this code creates a bar chart showing the frequency of incorrect predictions produced by the model for each digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_classes = model.predict_classes(x_test)\n",
    "\n",
    "# initialize arrays\n",
    "nums = np.arange(0, 10)\n",
    "wrong_out_dist = np.zeros((10,))\n",
    "wrong_out_label_dist = np.zeros((10,))\n",
    "\n",
    "# compare predictions to actual labels\n",
    "for i in range(len(prediction_classes)):\n",
    "    if prediction_classes[i] != y_test_raw[i]:\n",
    "        wrong_out_dist[prediction_classes[i]] += 1\n",
    "        wrong_out_label_dist[y_test_raw[i]] += 1\n",
    "\n",
    "# https://stackoverflow.com/questions/33203645/how-to-plot-a-histogram-using-matplotlib-in-python-with-a-list-of-data\n",
    "# https://www.programcreek.com/python/example/56587/matplotlib.pyplot.title\n",
    "plt.title(\"Incorrect outputs\")\n",
    "plt.xlabel(\"Output\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.bar(nums, wrong_out_dist, tick_label=nums)\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Incorrect outputs (actual label)\")\n",
    "plt.xlabel(\"Actual label\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.bar(nums, wrong_out_label_dist, tick_label=nums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As another demonstration, this code produces the top three digits that the model had trouble classifying.\n",
    "\n",
    "(which should be the three most poorly drawn digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions for each digit in the test set\n",
    "# (this differs from predict_classes, as this returns a probability distribution for each digit)\n",
    "predictions = model.predict(x_test)\n",
    "# get the highest prediction value for each digit (0-1 because of softmax)\n",
    "confidence = [np.std(p) / max(p) for p in predictions]\n",
    "# get indexes of sorted confidence values (smallest to largest)\n",
    "# a small max value from a probility distribution suggests uncertainty\n",
    "confidence_sorted = np.argsort(confidence)\n",
    "\n",
    "# plot those three digits\n",
    "for i in range(3):\n",
    "    plt.imshow([255 - i for i in x_test_raw[confidence_sorted[i]]], cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
